---
title: "PROJET TUTORE (M2 SSD)"
author: "Saoudi Khaoula  "
date: "2024-10-28"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning=FALSE)
```

# Analyse descriptives - UT4M Cardio

L’objectif de ce script est de proposer des visuels permettant de se familiariser avec des données UT4M sur le comportement cardiaques des utltra-trailers. Nous présenterons également à la fin nos premières modélisation des données.

## Les bibliothèques nécessaires

```{r, echo=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(readxl)
library(stringr)
library(tibble)  
library(broom)
library(zoo)
library(splines)
library(tidyverse)
library(gtools)  

```


# Import et traitement des données

## Importation des données

Dans cette première étape, nous importons les données de la feuille 'Tableau_gl' du fichier Excel contenant les informations complètes de l'étude UT4M.

```{r, echo=FALSE, message=FALSE}

#'Tableau_gl' du fichier Excel
data <- read_excel ("Données complètes UT4M final120419 avec Data cardio.xlsx", sheet = "Tableau_gl")
head(data)
```

## Sélection des colonnes d'intérêt

Nous avons extrait les colonnes de mesures générales (24 à 213) et les mesures cardiaques (267 à la fin), puis affiché les trois premières lignes des mesures cardiaques pour validation.

```{r, echo=FALSE, message=FALSE}
#On Sélectionne les colonnes d'intérêt: les 5 premières colonnes (A à E) et les colonnes "JG" à "SD"
# Cela correspond aux colonnes 1 à 5 et aux colonnes qui se situent dans la plage JG à SD
data_selected1 <- data[, c(1:5, 267:ncol(data))]
# Affichons les trois premières lignes de "mesures_cardiaques"
head(data_selected1, 3)
```
## Remarque

le volume de l’oreillette gauche et droite sont nomme dans la viste de PRE par "VOL_ODI_PRE" "VOL_OGI_PRE" alors que dans les autres visites il sont nomme "VOLODI_" "VOLOGI_"

## Renommer les variables "VOL_ODI_PRE" "VOL_OGI_PRE"

```{r, echo=FALSE, message=FALSE}
# Renommer les colonnes spécifiées
names(data_selected1) <- gsub("VOL_ODI_PRE", "VOLODI_PRE", names(data_selected1))
names(data_selected1) <- gsub("VOL_OGI_PRE", "VOLOGI_PRE", names(data_selected1))

#print(names(data_selected))
```

```{r, echo=FALSE, message=FALSE}

# Sélectionner les colonnes COURSE, CODE_SUJET en premier, puis les autres colonnes spécifiées
data_selected <- data_selected1 %>%
  select(COURSE, CODE_SUJET, matches("VOLOGI|VOLODI|VTDVGI|VTSVGI|FE2D|FRVD|STDi|STSi"))

# Affichons les premières lignes des colonnes sélectionnées
head(data_selected)


```

## Remplacement des valeurs temporelles et des -1 par NA

Dans cette étape, nous définissons une fonction qui remplace les valeurs temporelles présentes dans les noms des colonnes par des valeurs numériques, et remplace également les valeurs -1 par des valeurs manquantes (NA).
```{r, echo=FALSE, message=FALSE}
# Fonction pour remplacer les valeurs temporelles dans les noms de colonnes et -1 par NA dans les données
replace_time_values <- function(df) {
  # Remplacons les valeurs temporelles dans les noms de colonnes
  colnames(df) <- str_replace_all(colnames(df), c("PRE" = "-2", "POST" = "1", "D_2" = "3", "D_5" = "6", "D_10" = "11"))
  
  # Remplacons -1 par NA dans tout le dataset
  df[df == -1] <- NA
  
  return(df)
}

# Appliquons la fonction aux données sélectionnées
data_replaced <- replace_time_values(data_selected)
head(data_replaced)
```


## Renommer CODE_SUJET en Individu

```{r, echo=FALSE, message=FALSE}
data_replaced <- data_replaced %>%
  group_by(COURSE) %>%
  mutate(CODE_SUJET = paste("Individu", row_number())) %>%
  ungroup()

head(data_replaced)

```

## Transformation des données en format long

Ici, nous transformons les données de format large à format long tout en conservant certaines colonnes, comme 'CODE_SUJET' et 'COURSE'.

```{r, echo=FALSE, message=FALSE}

# Transformation des données en format long
data_long <- data_replaced %>%
  pivot_longer(
    cols = -c(COURSE, CODE_SUJET), 
    names_to = "Variable",
    values_to = "Valeur" 
  ) %>%
  separate(Variable, into = c("Variable", "Temps"), sep = "_", extra = "merge") 
head(data_long)

```

## Résumés statistiques

Réalisons maintenant les résumés statistiques sur nos 8 variables d’intérêt.

```{r, echo=FALSE, message=FALSE}

# les variables d'intérêt
variables_of_interest <- c("VOLOGI", "VOLODI", "VTDVGI", "VTSVGI", "FE2D", "FRVD", "STDi", "STSi")
data_filtered <- data_long %>%
  filter(Variable %in% variables_of_interest)

# les résumés statistiques pour chaque variable
statistical_summaries <- data_filtered %>%
  group_by(Variable) %>%
  summarise(
    Count = n(),
    Missing = sum(is.na(Valeur)),
    Min = min(Valeur, na.rm = TRUE),
    Q1 = quantile(Valeur, 0.25, na.rm = TRUE),
    Median = median(Valeur, na.rm = TRUE),
    Mean = mean(Valeur, na.rm = TRUE),
    Q3 = quantile(Valeur, 0.75, na.rm = TRUE),
    Max = max(Valeur, na.rm = TRUE),
    Missing_Percentage = Missing / Count * 100  #pourcentage des valeurs manquantes
  ) %>%
  ungroup()

print(statistical_summaries)


```


## Les valeurs manquantes 

Dans cette section, nous allons compter les valeurs manquantes en prenant en compte les courses, les vistes et les individus.



```{r, echo=FALSE, message=FALSE}
# le pourcentage de valeurs manquantes pour chaque variable individuelle
missing_percentage_by_variable <- data_long %>%
  group_by(Variable) %>%
  summarise(
    total_values = n(),  # Nombre total de valeurs
    total_missing = sum(is.na(Valeur)),  # Nombre total de valeurs manquantes
    percentage_missing = (total_missing / total_values) * 100  
  )

print("Pourcentage de valeurs manquantes par variable :")
print(missing_percentage_by_variable)

# Création du graphique de barres pour les valeurs manquantes
ggplot(missing_percentage_by_variable, aes(x = Variable, y = percentage_missing, fill = Variable)) +
  geom_col() +
  theme_minimal() +
  labs(x = "Variable", y = "Pourcentage de valeurs manquantes",
       title = "Proportion de valeurs manquantes par variable") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```
Le nombre de données manquantes par visite et par variable cardiaque :

```{r, echo=FALSE, message=FALSE}
# le nombre de données manquantes par Temps et Variable
missing_data_summary <- data_long %>%
  group_by(Temps, Variable) %>%
  summarise(Missing_Count = sum(is.na(Valeur)), .groups = 'drop')

missing_data_pivot <- missing_data_summary %>%
  pivot_wider(names_from = Variable, values_from = Missing_Count, values_fill = list(Missing_Count = 0))

print(missing_data_pivot)


```
Le nombre de données manquantes par sujet et par variable cardiaque :

```{r, echo=FALSE, message=FALSE}
missing_data_detailed_summary <- data_long %>%
  group_by(CODE_SUJET, Variable, COURSE) %>%
  summarise(Missing_Count = sum(is.na(Valeur)), .groups = 'drop')

missing_data_pivot <- missing_data_detailed_summary %>%
  pivot_wider(names_from = Variable, values_from = Missing_Count, values_fill = list(Missing_Count = 0)) %>%
  arrange(CODE_SUJET, COURSE)

print(missing_data_pivot)

```


# Visualisation

## Représentations graphiques

Nous allons créer des spaghetti plots pour visualiser l'évolution des variables cardiaques (comme la fréquence cardiaque et la pression artérielle) en fonction du temps, pour différentes courses (100 km, 4x40 km, 40 km, 160 km). Chaque sujet sera représenté par une courbe individuelle avec des points aux moments clés (PRE, POST, D2, D5, D10), et nous ajouterons une courbe moyenne en noir pour illustrer la tendance générale pour tous les sujets. Nous commencerons par filtrer les données selon la variable et la course, puis nous générerons les graphiques avec des courbes colorées pour chaque sujet et des points pour indiquer les valeurs spécifiques à chaque instant temporel.



```{r, echo=FALSE, message=FALSE}

create_spaghetti_plot <- function(data_long, variable, course) {
  data_filtered <- data_long %>% 
    filter(Variable == variable, COURSE == course)
  
  data_filtered <- data_filtered %>%
    mutate(Temps_Label = factor(Temps, levels = c(-2, 1, 3, 6, 11),
                                labels = c("PRE", "POST", "D2", "D5", "D10")))
  

  data_filtered <- data_filtered %>%
    group_by(CODE_SUJET) %>%
    mutate(Valeur = na.approx(Valeur, na.rm = FALSE)) %>%
    ungroup()
  
  ordered_sujets <- mixedsort(unique(data_filtered$CODE_SUJET))
  data_filtered$CODE_SUJET <- factor(data_filtered$CODE_SUJET, levels = ordered_sujets)
  sujet_colors <- rainbow(n = length(ordered_sujets))
  sujet_colors <- c(sujet_colors, "black") 

  # spaghetti plot avec une couleur distincte par sujet et la courbe moyenne en noir
  ggplot(data_filtered, aes(x = Temps_Label, y = Valeur, group = CODE_SUJET, color = CODE_SUJET)) +
    geom_line(alpha = 0.7, size = 1) +  
    geom_point(alpha = 0.9, size = 2) + 
    stat_summary(fun = mean, geom = "line", aes(group = 1, color = "Moyenne"), size = 1.5) +  
    stat_summary(fun = mean, geom = "point", aes(group = 1, color = "Moyenne"), size = 3) +  
    scale_color_manual(values = setNames(c(sujet_colors, "black"), c(ordered_sujets, "Moyenne"))) + 
    labs(title = paste("Spaghetti plot for", variable, "during", course, "km race"),
         x = "Time Points", y = "Value", color = "Code Sujet") +
    theme_minimal() +
    theme(legend.position = "right")  
}

```

Représentations visuelles des variables d’intérêts
Voici les spaghettis plot pour toutes les variables d’intérêt pour la course 100km 

```{r, echo=FALSE, message=FALSE}

create_spaghetti_plot(data_long, "FE2D", 100)
create_spaghetti_plot(data_long, "FRVD", 100)
create_spaghetti_plot(data_long, "VTDVGI", 100)
create_spaghetti_plot(data_long, "VTSVGI", 100)
create_spaghetti_plot(data_long, "STDi", 100)
create_spaghetti_plot(data_long, "STSi", 100)
create_spaghetti_plot(data_long, "VOLODI", 100)
create_spaghetti_plot(data_long, "VOLOGI", 100)
```

# Variabilité intra-individuelle et inter-individuelle 

## Moyenne et ecart-type par individu (intra-individuel)

Dans cette partie, nous donnons la moyenne et l’écart-type par individu sous forme de tableau, puis nous l’illustrons avec des représentations graphiques

```{r, echo=FALSE, message=FALSE}
variables_of_interest <- c("VOLOGI", "VOLODI", "VTDVGI", "VTSVGI", "FE2D", "FRVD", "STDi", "STSi")

# la moyenne et l'écart-type pour chaque CODE_SUJET, COURSE et Variable
data_summary <- data_long %>%
  filter(Variable %in% variables_of_interest) %>%
  group_by(CODE_SUJET, COURSE, Variable) %>%
  summarise(
    Mean = mean(Valeur, na.rm = TRUE),
    SD = sd(Valeur, na.rm = TRUE),
    .groups = 'drop'
  )

# les données par COURSE, en mettant les "100 km"
data_summary <- data_summary %>%
  arrange(desc(COURSE == "100"), COURSE)  


data_pivot <- data_summary %>%
  unite("Mean_SD", Mean, SD, sep=", ") %>%
  pivot_wider(
    names_from = Variable,
    values_from = Mean_SD,
    values_fill = list(Mean_SD = "NA")
  )

print(data_pivot)


```
## Creation du fonction de visualisation des graphiques 

```{r, echo=FALSE, message=FALSE}
create_individual_variability_plot <- function(data_long, variable, course) {

  data_filtered <- data_long %>%
    filter(COURSE == course, Variable == variable)

  # la moyenne et l'écart-type pour chaque individu
  data_stats <- data_filtered %>%
    group_by(CODE_SUJET) %>%
    summarise(
      Mean = mean(Valeur, na.rm = TRUE),
      SD = sd(Valeur, na.rm = TRUE),
      .groups = 'drop'
    )

  # graphique à barres avec des barres d'erreur
  p <- ggplot(data_stats, aes(x = factor(course), y = Mean, fill = factor(CODE_SUJET))) +
    geom_bar(stat = "identity", position = position_dodge(), width = 0.7) +
    geom_errorbar(aes(ymin = Mean - SD, ymax = Mean + SD), width = 0.25, position = position_dodge(0.7)) +
    labs(title = paste("Variabilité intra-individuelle pour", variable, "course", course, "km"),
         x = "course",
         y = "Moyenne") +
    scale_fill_brewer(palette = "Paired", name = "Individu") +
    theme_minimal() +
    theme(legend.position = "bottom")

  return(p)
}

```

## Visualisation graphique

```{r, echo=FALSE, message=FALSE}

plot1 <- create_individual_variability_plot(data_long, "VOLODI", 100)
print(plot1)
plot2 <- create_individual_variability_plot(data_long, "VOLOGI", 100)
print(plot2)

plot3 <- create_individual_variability_plot(data_long, "VTDVGI", 100)
print(plot3)
plot4 <- create_individual_variability_plot(data_long, "VTSVGI", 100)
print(plot4)
plot5 <- create_individual_variability_plot(data_long, "FE2D", 100)
print(plot5)
plot6 <- create_individual_variability_plot(data_long, "FRVD", 100)
print(plot6)
plot7 <- create_individual_variability_plot(data_long, "STDi", 100)
print(plot7)
plot8 <- create_individual_variability_plot(data_long, "STSi", 100)
print(plot8)


```

## Moyenne et ecart-type par course et par temps (inter-individuel)

Voici le résultat de la variabilité inter-individuel pour nos variables d’intérêts :

```{r, echo=FALSE, message=FALSE}

variables_of_interest <- c("VOLOGI", "VOLODI", "VTDVGI", "VTSVGI", "FE2D", "FRVD", "STDi", "STSi")

#la moyenne et de l'écart-type pour chaque COURSE, Temps, et Variable
data_summary <- data_long %>%
  filter(Variable %in% variables_of_interest) %>%
  group_by(COURSE, Temps, Variable) %>%
  summarise(
    Mean = mean(Valeur, na.rm = TRUE),
    SD = sd(Valeur, na.rm = TRUE),
    .groups = 'drop'
  )


temps_order <- c("-2", "1", "3", "6", "11") 
data_summary$Temps <- factor(data_summary$Temps, levels = temps_order)

data_pivot <- data_summary %>%
  unite("Mean_SD", Mean, SD, sep=", ") %>%
  pivot_wider(
    names_from = Variable,
    values_from = Mean_SD,
    values_fill = list(Mean_SD = "NA")
  )


data_pivot <- data_pivot %>%
  arrange(Temps, COURSE)


print(data_pivot)


```
## Creation du fonction de visualisation des graphiques
 
```{r, echo=FALSE, message=FALSE}

create_variability_plot <- function(data_long, variable) {
  # la variable spécifique
  data_stats <- data_long %>%
    filter(Variable == variable) %>%
    group_by(COURSE, Temps) %>%
    summarise(
      Mean = mean(Valeur, na.rm = TRUE),
      SD = sd(Valeur, na.rm = TRUE),
      .groups = 'drop'
    )

 
  time_labels <- setNames(c("PRE", "POST", "D_2", "D_5", "D_10"), c(-2, 1, 3, 6, 11))
  data_stats$Temps <- factor(time_labels[as.character(data_stats$Temps)], levels = time_labels)

  # graphique avec les moyennes pour chaque course à chaque temps
  p <- ggplot(data_stats, aes(x = Temps, y = Mean, fill = COURSE)) +
    geom_bar(stat = "identity", position = position_dodge(), width = 0.7) +
    geom_errorbar(aes(ymin = Mean - SD, ymax = Mean + SD), width = 0.2, position = position_dodge(0.7)) +
    scale_fill_brewer(palette = "Set3", name = "Course") +
    labs(title = paste("Variabilité inter-individuelle par course pour", variable),
         x = "Temps",
         y = paste(variable, "moyen")) +
    theme_minimal() +
    theme(legend.title = element_text(size = 12), legend.text = element_text(size = 10),
          plot.title = element_text(hjust = 0.5))

  return(p)
}


```

## Visualisation graphique

```{r, echo=FALSE, message=FALSE}
plot9 <- create_variability_plot(data_long, "VOLODI")
print(plot9)
plot10 <- create_variability_plot(data_long, "VOLOGI")
print(plot10)
plot11 <- create_variability_plot(data_long, "VTDVGI")
print(plot11)
plot12 <- create_variability_plot(data_long, "VTSVGI")
print(plot12)
plot13 <- create_variability_plot(data_long, "FRVD")
print(plot13)
plot14 <- create_variability_plot(data_long, "FE2D")
print(plot14)
plot15 <- create_variability_plot(data_long, "STDi")
print(plot15)
plot16 <- create_variability_plot(data_long, "STSi")
print(plot16)
```

# Tests d’hypothèses

Dans cette partie, nous allons faire des tests d’égalité des moyennes entre PRE et POST (-2 et 1) pour chaque course.

```{r, echo=FALSE, message=FALSE}

mean_test <- function(df, courses) {
  all_results <- list()

  variables_of_interest <- c("VOLODI", "VOLOGI", "VTDVGI", "VTSVGI", "FE2D", "FRVD", "STDi", "STSi")

  # Boucle sur chaque variable pour effectuer des tests
  for (val_study in variables_of_interest) {

    df_filtered <- df %>%
      filter(COURSE %in% courses, Temps %in% c(-2, 1), Variable == val_study) %>%
      mutate(
        Time = ifelse(Temps == -2, "PRE", "POST")
      ) %>%
      select(COURSE, CODE_SUJET, Time, Valeur) %>%
      pivot_wider(
        id_cols = c(COURSE, CODE_SUJET),
        names_from = Time,
        values_from = Valeur,
        values_fill = list(Valeur = NA)
      ) %>%
      drop_na()


    results <- df_filtered %>%
      group_by(COURSE) %>%
      summarise(
        p_value = t.test(PRE, POST, paired = TRUE)$p.value,
        .groups = 'drop'
      ) %>%
      mutate(Variable = val_study) %>%
      select(COURSE, Variable, p_value)

    all_results[[val_study]] <- results
  }

  combined_results <- bind_rows(all_results)

  final_results <- combined_results %>%
    pivot_wider(
      names_from = Variable,
      values_from = p_value,
      id_cols = COURSE
    )

  return(final_results)
}
```

Les pvaleurs non corrigées associé à chaque tests :

```{r, echo=FALSE, message=FALSE}
courses <- c(100, 160, 40)
p_values <- mean_test(data_long, courses)
print("P-values Brutes:")
print(p_values)
```


Voici les résultats avec les corrections de Benjamini-Yakutelli et Benjamini-Hochberg 

```{r, echo=FALSE, message=FALSE}
# Correction Benjamini-Hochberg (BH)
p_values_bh <- p_values %>%
  mutate(across(-COURSE, ~ p.adjust(.x, method = "BH")))

print("P-values corrigées avec Benjamini-Hochberg (BH):")
print(p_values_bh)

# Correction Benjamini-Yekutieli (BY)
p_values_by <- p_values %>%
  mutate(across(-COURSE, ~ p.adjust(.x, method = "BY")))

print("P-values corrigées avec Benjamini-Yekutieli (BY):")
print(p_values_by)
```


